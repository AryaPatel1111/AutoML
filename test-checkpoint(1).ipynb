{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input The File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to ask user for the file location\n",
    "#and return the dataset\n",
    "def userFilePath():\n",
    "    filepath = input('Enter location of the file: ')\n",
    "    data = pd.read_csv(filepath, low_memory=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask them features and target if model is Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the name of the features and variable\n",
    "#to put comma after each feature\n",
    "def selectFeatures():\n",
    "    x = input(\"Enter the names of features : \")\n",
    "    features=x.split(',')\n",
    "    target = input(\"Enter the target between '' : \")\n",
    "    return (features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the data types of each column\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to count the number of null values in each column\n",
    "count_null=data[data.columns].isna().sum()\n",
    "print(dict(count_null))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To replace null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=len(data.index)\n",
    "for i in features:\n",
    "    k=count_null[i]\n",
    "    if k!=0:\n",
    "        if k>(rows/2):\n",
    "            data.drop([i], axis = 1)\n",
    "        else:\n",
    "            print('How do u want to replace the null values for feature: ',i)\n",
    "            print('1. with 0\\n2.with mean\\n3.with median\\n4.with mode')\n",
    "            ch=int(input())\n",
    "            if ch==1:\n",
    "                data[i] = data[i].fillna(0)\n",
    "            elif ch==2:\n",
    "                mean=data[i].mean()\n",
    "                data[i] = data[i].fillna(mean)\n",
    "            elif ch==3:\n",
    "                med=data[i].median()\n",
    "                data[i] = data[i].fillna(med)\n",
    "            elif ch==2:\n",
    "                mode=data[i].mode()\n",
    "                data[i] = data[i].fillna(mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If they don't know features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "def featsel(data):\n",
    "    ax = sns.heatmap(data, annot=True, vmin=0, vmax=1)\n",
    "    print('Check the value printed on each block in the target column.\\n')\n",
    "    print('Value of covariance nearer to 1 better the feature related with target.\\n')\n",
    "    print('After selecting the features input them.\\n\\n\\n')\n",
    "    \n",
    "    #Input the name of the features and variable\n",
    "    features, target = selectFeatures()\n",
    "    X = data.loc[:,[features]]    \n",
    "    y = data.loc[:,[target]]     \n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If they know the features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the features into the X and y respectively and return it\n",
    "def featget(data):\n",
    "    features, target = selectFeatures()\n",
    "    X = data.loc[:,[features]]\n",
    "    y = data.loc[:,[target]]     \n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Function that returns X after performing oneHotEncoding\n",
    "# columnNumber --> takes the columnNumber for which one hot encoding is to be done\n",
    "def oneHotEncoding(X, columnNumber):\n",
    "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [columnNumber])], remainder='passthrough')\n",
    "    X = np.array(ct.fit_transform(X))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# X--> takes only a single column\n",
    "def labelEncodingColumn(X):\n",
    "    le = LabelEncoder()\n",
    "    X = le.fit_transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binariztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "def binarize(X_train,X_test):\n",
    "    binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "    binary_X = binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test split using sklearn\n",
    "#Do this after you've asked which ML model they want."
    "#Will help you in doing the accuracy test."
    "def split_dataset(X, y, testSize, randomState):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # testSize--> defines the size of the test from the dataset(takes decimal less than 1)\n",
    "    # randomState --> takes integer input\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testSize, random_state = randomState)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard(X_train,X_test):\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train,X_test):\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    scaler = Normalizer().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models Start Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearReg(X_train,X_test):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the accuracy of the model\n",
    "#higher the value of R2 score, the better the model fits your data\n",
    "def acc_linearReg(y_pred,y_test):\n",
    "    from sklearn.metrics import r2_score\n",
    "    print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(y_pred - y_test)))\n",
    "    print(\"Residual sum of squares (MSE): %.2f\" % np.mean((y_pred - y_test) ** 2))\n",
    "    print(\"R2-score: %.2f\" % r2_score(y_pred, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logReg(X_train,X_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logr = LogisticRegression()\n",
    "    logr.fit(X_train,y_train)\n",
    "    y_pred = logr.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#higher the jaccard score, the better the model fits your data\n",
    "def acc_logReg(y_pred,y_test):\n",
    "    from sklearn.metrics import jaccard_similarity_score\n",
    "    print(\"Jaccard similarity score: %.2f\" % jaccard_similarity_score(y_test, y_pred))\n",
    "    from sklearn.metrics import log_loss\n",
    "    print(\"Log loss: %.2f\" %log_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SV Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svcModel(X_train,X_test):\n",
    "    from sklearn.svm import SVC\n",
    "    svc = SVC(kernel='linear')\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#higher the value of F1 score, the better the model fits your data\n",
    "def acc_svcModel(y_pred,y_test):\n",
    "    from sklearn.metrics import f1_score\n",
    "    print(\"F1 score: %.2f\" %f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnModel(X_train,X_test,n):\n",
    "    from sklearn import neighbors\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=n)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_knnModel(y_pred,y_test):\n",
    "    from sklearn import metrics\n",
    "    print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, neigh.predict(X_train)))\n",
    "    print(\"Test set Accuracy: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the functions and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = userFilePath()\n",
    "print(\"Enter 1. if you know which features to enter: \")\n",
    "print(\"Enter 2. if you don't know fetures to enter: \")\n",
    "option = input()\n",
    "if(option == 1):\n",
    "    X,y = featget()\n",
    "else:\n",
    "    X,y = featsel()\n",
    "    \n",
    "print(\"Do you want to perform One Hot Encoding?[y/n]\")\n",
    "if(input() == 'y'):\n",
    "    X = oneHotEncoding(X, input('Enter the Column number : '))\n",
    "\n",
    "\n",
    "print('Do you want to perform Label Encoding?[y/n]')\n",
    "if(input() == 'y'):\n",
    "    X = labelEncodingColumn(X)\n",
    "    \n",
    "standardizationYN = input(\"Do you want to perform Standardization ?[y/n]\")\n",
    "normalizationYN = input(\"Do you want to perform Normalization ?[y/n]\")\n",
    "#after this we have to call the train test split and other prediction models\n",
    "test_size = 0.1\n",
    "while(test_size <= 0.45):\n",
    "    X_train,X_test,y_train,y_test = split_dataset(X, y, teest_size, 0)\n",
    "    if(standardizationYN == 'y'):\n",
    "        X_train, X_test = standard(X_train,X_test)\n",
    "    \n",
    "    if(normalizationYN == 'y'):\n",
    "        X_train, X_test = normalize(X_train,X_test)\n",
    "    test_size+=0.05\n",
    "    #Now when the accuracy calculation function is done \n",
    "    #call all the ML model inside them and then print their respective accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What type of ML model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Enter 1. for Linear Regression model: \")\n",
    "print(\"Enter 2. for Support Vector Regression model: \")\n",
    "print(\"Enter 3. for Logistic Regression model: \")\n",
    "print(\"Enter 4. for K nearest neighbours model: \")\n",
    "model=input()\n",
    "if model==1:\n",
    "    linearReg(X_train,X_test)\n",
    "    acc_linearReg(y_pred,y_test)\n",
    "elif model==2:\n",
    "    svcModel(X_train,X_test)\n",
    "    acc_svcModel(y_pred,y_test)\n",
    "elif model==3:\n",
    "    logReg(X_train,X_test)\n",
    "    acc_logReg(y_pred,y_test)\n",
    "elif model==4:\n",
    "    n=input(\"Enter the value for K\")\n",
    "    knnModel(X_train,X_test,n)\n",
    "    acc_knnModel(y_pred,y_test)\n",
    "else:\n",
    "    print(\"Enter a correct choice\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
