{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input The File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to ask user for the file location\n",
    "#and return the dataset\n",
    "def userFilePath():\n",
    "    filepath = input('Enter location of the file: ')\n",
    "    data = pd.read_csv(filepath, low_memory=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ask them features and target if model is Supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the name of the features and variable\n",
    "#to put comma after each feature\n",
    "def selectFeatures():\n",
    "    x = input(\"Enter the names of features : \")\n",
    "    features=x.split(',')\n",
    "    target = input(\"Enter the target between '' : \")\n",
    "    return features, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To replace null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceNull(data, features):\n",
    "    #to count the number of null values in each column\n",
    "    count_null=data[data.columns].isna().sum()\n",
    "    count_null=dict(count_null)\n",
    "    rows=len(data.index)\n",
    "    for i in features:\n",
    "        k=count_null[i]\n",
    "        if k!=0:\n",
    "            if k>(rows/2):\n",
    "                data.drop([i], axis = 1)\n",
    "            else:\n",
    "                print('How do u want to replace the null values for feature: ',i)\n",
    "                print('1. with 0\\n2.with mean\\n3.with median\\n4.with mode')\n",
    "                ch=int(input())\n",
    "                if ch==1:\n",
    "                    data[i] = data[i].fillna(0)\n",
    "                elif ch==2:\n",
    "                    mean=data[i].mean()\n",
    "                    data[i] = data[i].fillna(mean)\n",
    "                elif ch==3:\n",
    "                    med=data[i].median()\n",
    "                    data[i] = data[i].fillna(med)\n",
    "                elif ch==2:\n",
    "                    mode=data[i].mode()\n",
    "                    data[i] = data[i].fillna(mode)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return X and y according to the features entered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the features into the X and y respectively and return it\n",
    "def featget(data, features, target):\n",
    "    X = data.loc[:,features]\n",
    "    print(target)\n",
    "    y = data.loc[:,target]     \n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#Function that returns X after performing oneHotEncoding\n",
    "# columnNumber --> takes the columnNumber for which one hot encoding is to be done\n",
    "def oneHotEncoding(X, columnNumber):\n",
    "    ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [columnNumber])], remainder='passthrough')\n",
    "    X = np.array(ct.fit_transform(X))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# X--> takes only a single column\n",
    "def labelEncodingColumn(X):\n",
    "    le = LabelEncoder()\n",
    "    X = le.fit_transform(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binariztion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "def binarize(X_train,X_test):\n",
    "    binarizer = Binarizer(threshold=0.0).fit(X)\n",
    "    binary_X = binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test split using sklearn\n",
    "def split_dataset(X, y, testSize, randomState):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # testSize--> defines the size of the test from the dataset(takes decimal less than 1)\n",
    "    # randomState --> takes integer input\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testSize, random_state = randomState)\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def standard(X_train,X_test):\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X_train,X_test):\n",
    "    from sklearn.preprocessing import Normalizer\n",
    "    scaler = Normalizer().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return (X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Models Start Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linearReg(X_train,X_test, y_train):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    y_pred = lr.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logReg(X_train,X_test, y_train):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    logr = LogisticRegression()\n",
    "    logr.fit(X_train,y_train)\n",
    "    y_pred = logr.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SV Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svcModel(X_train,X_test, y_train):\n",
    "    from sklearn.svm import SVC\n",
    "    svc = SVC(kernel='linear')\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred = svc.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knnModel(X_train,X_test,y_train,n):\n",
    "    from sklearn import neighbors\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=n, metric = 'minkowski', p=2)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the accuracy of the model\n",
    "#higher the value of R2 score, the better the model fits your data\n",
    "def accuracy(y_pred,y_test):\n",
    "    from sklearn.metrics import r2_score\n",
    "    return r2_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling the functions and predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter location of the file: C:/Users/aryam/OneDrive/Documents/ML_Projects/SinkingTitanic/train.csv\n",
      "Enter the names of features : Pclass,Age,Sex\n",
      "Enter the target between '' : Survived\n",
      "How do u want to replace the null values for feature:  Age\n",
      "1. with 0\n",
      "2.with mean\n",
      "3.with median\n",
      "4.with mode\n",
      "2\n",
      "Survived\n",
      "Do you want to perform One Hot Encoding?[y/n]\n",
      "n\n",
      "Do you want to perform Label Encoding?[y/n]\n",
      "y\n",
      "Enter the column name : Sex\n",
      "Do you want to perform Standardization ?[y/n]n\n",
      "Do you want to perform Normalization ?[y/n]y\n"
     ]
    }
   ],
   "source": [
    "filepath = input('Enter location of the file: ')\n",
    "df = pd.read_csv(filepath, low_memory=True)\n",
    "#replacing null values\n",
    "features, target = selectFeatures()\n",
    "replaceNull(df, features)\n",
    "\n",
    "X,y = featget(df,features, target)\n",
    "    \n",
    "\n",
    "print(\"Do you want to perform One Hot Encoding?[y/n]\")\n",
    "if(input() == 'y'):\n",
    "    X = oneHotEncoding(X, input('Enter the Column number : '))\n",
    "\n",
    "\n",
    "print('Do you want to perform Label Encoding?[y/n]')\n",
    "if(input() == 'y'):\n",
    "    col_num = input('Enter the column name : ')\n",
    "    X[col_num] = labelEncodingColumn(X[col_num])\n",
    "    \n",
    "standardizationYN = input(\"Do you want to perform Standardization ?[y/n]\")\n",
    "normalizationYN = input(\"Do you want to perform Normalization ?[y/n]\")\n",
    "\n",
    "#after this we have to call the train test split and other prediction models\n",
    "test_size = 0.1\n",
    "while(test_size <= 0.45):\n",
    "    X_train,X_test,y_train,y_test = split_dataset(X, y, test_size, 0)\n",
    "    if(standardizationYN == 'y'):\n",
    "        X_train, X_test = standard(X_train,X_test)\n",
    "    \n",
    "    if(normalizationYN == 'y'):\n",
    "        X_train, X_test = normalize(X_train,X_test)\n",
    "    test_size+=0.05\n",
    "    #Now when the accuracy calculation function is done \n",
    "    #call all the ML model inside them and then print their respective accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What type of ML model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 1. for Regression: \n",
      "Enter 2. for Classification: \n",
      "2\n",
      "\n",
      "Enter the value for K5\n",
      "          Logistic Regression  K-nearest neighbours\n",
      "Accuracy           -12.740559              0.038293\n",
      "\n",
      "Enter 1. for Logistic Regression: \n",
      "\n",
      "Enter 2. for K-nearest neighbours: \n",
      "2\n",
      "\n",
      "Prediction for K-nearest neighbours model: \n",
      "     Survived\n",
      "0           0\n",
      "1           0\n",
      "2           0\n",
      "3           1\n",
      "4           1\n",
      "..        ...\n",
      "396         0\n",
      "397         0\n",
      "398         1\n",
      "399         0\n",
      "400         0\n",
      "\n",
      "[401 rows x 1 columns] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter 1. for Regression: \")\n",
    "print(\"Enter 2. for Classification: \")\n",
    "c=int(input())\n",
    "if c==1:\n",
    "    y_pred1=linearReg(X_train,X_test, y_train)\n",
    "    p=accuracy(y_pred1,y_test)\n",
    "    y_pred2=svcModel(X_train,X_test, y_train)\n",
    "    q=accuracy(y_pred2,y_test)\n",
    "    acc={'Linear Regression':p,'Support Vector Regression':q}\n",
    "    table = pd.DataFrame(acc, columns = ['Linear Regression','Support Vector Regression'], index=['Accuracy'])\n",
    "    print(table)\n",
    "    print(\"Enter 1. for Linear Regression: \")\n",
    "    print(\"Enter 2. for Support Vector Regression: \")\n",
    "    result=int(input())\n",
    "    if result==1:\n",
    "        print(\"Prediction for Linear Regression model: \")\n",
    "        output = pd.DataFrame({target: y_pred1})\n",
    "        print(output,'\\n')\n",
    "    else:\n",
    "        print(\"\\nPrediction for Support Vector Regression model: \")\n",
    "        output = pd.DataFrame({target: y_pred2})\n",
    "        print(output,'\\n')\n",
    "elif c==2:  \n",
    "    y_pred1=logReg(X_train,X_test, y_train)\n",
    "    p=accuracy(y_pred1,y_test)\n",
    "    n=int(input(\"\\nEnter the value for K\"))\n",
    "    y_pred2=knnModel(X_train,X_test, y_train, n)\n",
    "    q=accuracy(y_pred2,y_test)\n",
    "    acc={'Logistic Regression':p,'K-nearest neighbours':q}\n",
    "    table = pd.DataFrame(acc, columns = ['Logistic Regression','K-nearest neighbours'], index=['Accuracy'])\n",
    "    print(table)\n",
    "    print(\"\\nEnter 1. for Logistic Regression: \")\n",
    "    print(\"\\nEnter 2. for K-nearest neighbours: \")\n",
    "    result=int(input())\n",
    "    if p>q:\n",
    "        print(\"Prediction for Logistic Regression model: \")\n",
    "        output = pd.DataFrame({target: y_pred1})\n",
    "        print(output,'\\n')\n",
    "    else:\n",
    "        print(\"\\nPrediction for K-nearest neighbours model: \")\n",
    "        output = pd.DataFrame({target: y_pred2})\n",
    "        print(output,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
